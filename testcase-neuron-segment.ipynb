{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n#         break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-25T04:59:53.727378Z","iopub.execute_input":"2021-12-25T04:59:53.728299Z","iopub.status.idle":"2021-12-25T04:59:53.756620Z","shell.execute_reply.started":"2021-12-25T04:59:53.728186Z","shell.execute_reply":"2021-12-25T04:59:53.755845Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nfrom torch import nn\nfrom pandas import DataFrame as DF\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom sklearn.metrics import accuracy_score, f1_score\nimport matplotlib.pylab as plt\nfrom skimage import io, transform\nfrom torchvision import transforms\nfrom albumentations import (HorizontalFlip, VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:16.675367Z","iopub.execute_input":"2021-12-25T05:08:16.675660Z","iopub.status.idle":"2021-12-25T05:08:20.916513Z","shell.execute_reply.started":"2021-12-25T05:08:16.675632Z","shell.execute_reply":"2021-12-25T05:08:20.915862Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dirct = '../input/sartorius-cell-instance-segmentation'\n\ntraindf = pd.read_csv(dirct + \"/train.csv\")\ntraindf.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:27.296614Z","iopub.execute_input":"2021-12-25T05:08:27.296888Z","iopub.status.idle":"2021-12-25T05:08:28.027228Z","shell.execute_reply.started":"2021-12-25T05:08:27.296859Z","shell.execute_reply":"2021-12-25T05:08:28.026255Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"imagename = traindf['id'].unique()[0]\ndfimage = traindf[traindf['id']==imagename]\nannota_all = dfimage['annotation']\nprint(annota_all[2])\n\nimage = io.imread(dirct + '/train/' + imagename + '.png') \nplt.imshow(image)\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:30.460508Z","iopub.execute_input":"2021-12-25T05:08:30.460987Z","iopub.status.idle":"2021-12-25T05:08:30.852857Z","shell.execute_reply.started":"2021-12-25T05:08:30.460934Z","shell.execute_reply":"2021-12-25T05:08:30.851859Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"annot = rle_decode(annota_all[2], image.shape)\nprint(annot)\nplt.imshow(annot)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:40.101787Z","iopub.execute_input":"2021-12-25T05:08:40.102352Z","iopub.status.idle":"2021-12-25T05:08:40.383446Z","shell.execute_reply.started":"2021-12-25T05:08:40.102310Z","shell.execute_reply":"2021-12-25T05:08:40.382537Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def rle_decode(rle_annota, shape, color = 1):\n    s = rle_annota.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.float32)\n    for i in range(len(starts)):\n        lo = starts[i]\n        hi = ends[i]\n        img[lo:hi] = color\n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:36.863582Z","iopub.execute_input":"2021-12-25T05:08:36.864141Z","iopub.status.idle":"2021-12-25T05:08:36.871626Z","shell.execute_reply.started":"2021-12-25T05:08:36.864091Z","shell.execute_reply":"2021-12-25T05:08:36.870749Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"decode mask for a certain image\"\ndef create_mask(df_train, img_id, shape):\n    dfimage = df_train[df_train['id'] == img_id]\n    annota_all = dfimage['annotation'].tolist()\n    img_mask = np.zeros(shape)\n    for i in range(len(annota_all)):\n        mask_i = rle_decode(annota_all[i], shape)\n        img_mask += mask_i\n    img_mask = img_mask.clip(0, 1)\n    return np.array(img_mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:38.414583Z","iopub.execute_input":"2021-12-25T05:08:38.415258Z","iopub.status.idle":"2021-12-25T05:08:38.421466Z","shell.execute_reply.started":"2021-12-25T05:08:38.415215Z","shell.execute_reply":"2021-12-25T05:08:38.420705Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"a = create_mask(traindf, imagename, image.shape)\nplt.imshow(a)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:08:42.687603Z","iopub.execute_input":"2021-12-25T05:08:42.687919Z","iopub.status.idle":"2021-12-25T05:08:43.187187Z","shell.execute_reply.started":"2021-12-25T05:08:42.687886Z","shell.execute_reply":"2021-12-25T05:08:43.186170Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self, df: pd.core.frame.DataFrame, train_pct, train = bool):\n        self.Image = (224, 224)\n        self.RESNET_MEAN = (0.485, 0.456, 0.406)\n        self.RESNET_STD = (0.229, 0.224, 0.225)\n        self.df = df\n        self.dir = data_dir['TRAIN_PATH']\n        self.gb = self.df.groupby('id')\n #       self.trans = transforms.Compose([Resize(self.Image), ToTensor()])\n#         self.trans = transforms.Compose([transforms.ToPILImage(),\n#                                          transforms.Resize(self.Image),\n#                                          transforms.RandomHorizontalFlip(),\n#                                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                                          std=[0.229, 0.224, 0.225]),\n#                                          transforms.ToTensor()])\n        self.trans = Compose([Resize(self.Image[0], self.Image[1]), \n                                   Normalize(mean=self.RESNET_MEAN[0], std= self.RESNET_STD[0], p=1), \n                                   HorizontalFlip(p=0.5),\n                                   VerticalFlip(p=0.5)])\n        all_img = np.array(df.id.unique())  #create an array for all image id\n        np.random.seed(42)\n        idx_shuf = np.random.permutation(len(all_img))  #shuffle the dataset\n        num_train = int(len(all_img)*train_pct) #percent of training set\n        if train:\n            self.img_sf = all_img[idx_shuf[:num_train]]\n        else:\n            self.img_sf = all_img[idx_shuf[num_train:]]\n            \n    def __len__(self):\n        return len(self.img_sf)\n    \n    #get image sample with idx from the dataset for each item\n    def __getitem__(self, idx):\n        img_samp = self.img_sf[idx]\n        dfimage = self.gb.get_group(img_samp)#traindf[traindf['id']==img_samp] #each id has lots of img, group them\n        image_path = os.path.join(self.dir, img_samp) + \".png\"\n        \n        image = io.imread(image_path)\n        mask = create_mask(self.df, img_samp, image.shape)\n        mask = (mask >= 1).astype('float32')\n        augmented = self.trans(image=image, mask=mask)\n        img_aug = augmented['image']\n        msk_aug = augmented['mask']\n        img_aug = img_aug.astype('float32')\n        return img_aug.reshape((1, self.Image[0], self.Image[1])), msk_aug.reshape((1, self.Image[0], self.Image[1]))","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:46.372210Z","iopub.execute_input":"2021-12-25T05:09:46.372534Z","iopub.status.idle":"2021-12-25T05:09:46.390879Z","shell.execute_reply.started":"2021-12-25T05:09:46.372502Z","shell.execute_reply":"2021-12-25T05:09:46.389747Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\"specify data directories, join means add \\with file names\"\nDATA_PATH = '../input/sartorius-cell-instance-segmentation'\ndata_dir = { 'SAMPLE_SUBMISSION': os.path.join(DATA_PATH, 'train'),\n             'TRAIN_CSV': os.path.join(DATA_PATH, 'train.csv'),\n             'TRAIN_PATH': os.path.join(DATA_PATH, 'train'),\n             'TEST_PATH': os.path.join(DATA_PATH, 'test')}\nprint(data_dir['TRAIN_CSV'])","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:18.708706Z","iopub.execute_input":"2021-12-25T05:09:18.709593Z","iopub.status.idle":"2021-12-25T05:09:18.715570Z","shell.execute_reply.started":"2021-12-25T05:09:18.709545Z","shell.execute_reply":"2021-12-25T05:09:18.714975Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"img_train = Data(pd.read_csv(data_dir['TRAIN_CSV']), 0.9, train=True) \nimg_load  = DataLoader(img_train, batch_size=16, num_workers=2, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:48.698048Z","iopub.execute_input":"2021-12-25T05:09:48.698319Z","iopub.status.idle":"2021-12-25T05:09:49.429350Z","shell.execute_reply.started":"2021-12-25T05:09:48.698292Z","shell.execute_reply":"2021-12-25T05:09:49.428171Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"img_test = Data(pd.read_csv(data_dir['TRAIN_CSV']), 0.9, train=False) #traindf def early on top\ntest_load = DataLoader(img_test, batch_size=4, num_workers=2, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:50.932414Z","iopub.execute_input":"2021-12-25T05:09:50.932714Z","iopub.status.idle":"2021-12-25T05:09:51.553958Z","shell.execute_reply.started":"2021-12-25T05:09:50.932672Z","shell.execute_reply":"2021-12-25T05:09:51.550633Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(test_load))\nimages, masks = batch #first minibatch\nprint(f\"image shape: {images.shape},\\nmask shape:{masks.shape},\\nbatch len: {len(batch)}\")\nprint(images.dtype, masks.dtype)\nplt.figure(figsize=(20, 20))\n        \nplt.subplot(1, 3, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(images[1][0])\nplt.title('Original image')\n\nplt.subplot(1, 3, 2)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(masks[1][0])\nplt.title('Mask')\n\nplt.subplot(1, 3, 3)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(images[1][0])\nplt.imshow(masks[1][0],alpha=0.2)\nplt.title('Both')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:52.467675Z","iopub.execute_input":"2021-12-25T05:09:52.468259Z","iopub.status.idle":"2021-12-25T05:09:54.422762Z","shell.execute_reply.started":"2021-12-25T05:09:52.468203Z","shell.execute_reply":"2021-12-25T05:09:54.419376Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(masks[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:57.554868Z","iopub.execute_input":"2021-12-25T05:09:57.555872Z","iopub.status.idle":"2021-12-25T05:09:57.622609Z","shell.execute_reply.started":"2021-12-25T05:09:57.555790Z","shell.execute_reply":"2021-12-25T05:09:57.621707Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"whole batch\",len(img_train), \"num of minibatch\", len(img_load), \"with batch size 16\")","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:09:59.977835Z","iopub.execute_input":"2021-12-25T05:09:59.978568Z","iopub.status.idle":"2021-12-25T05:09:59.985842Z","shell.execute_reply.started":"2021-12-25T05:09:59.978524Z","shell.execute_reply":"2021-12-25T05:09:59.984827Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\"construct U-Net from scratch\"\nclass DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch, kernel):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential( \n            nn.Conv2d(in_ch, out_ch, kernel_size = kernel, stride=1, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, kernel_size = kernel, stride=1, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n         )\n    def forward(self, x):\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:01.880013Z","iopub.execute_input":"2021-12-25T05:10:01.880558Z","iopub.status.idle":"2021-12-25T05:10:01.888691Z","shell.execute_reply.started":"2021-12-25T05:10:01.880521Z","shell.execute_reply":"2021-12-25T05:10:01.887851Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class Down(nn.Module):\n    def __init__(self, in_ch, out_ch, kernel):\n        super().__init__()\n        self.down = nn.Sequential(nn.MaxPool2d(2,2),\n                                 DoubleConv(in_ch, out_ch, kernel))   #how Down class inherits DoubleConv?\n        \n    def forward(self, x):\n        x = self.down(x)\n        return x\n    \nclass Up(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch //2, in_ch //2, kernel_size = 2, stride = 2)\n        self.conv = DoubleConv(in_ch, out_ch, 3) \n        \n    def forward(self, feature, context):\n        x = self.up(feature)\n        \n        skip = torch.cat([x, context], dim = 1)   #concatenate context&feature map\n        up_x = self.conv(skip)          \n        return up_x\n\nclass out_layer(nn.Module):\n    def __init__(self, in_ch, num_class):\n        super().__init__()\n        self.conv = nn.Conv2d(in_ch, num_class, 1) #final layer by 1x1 conv\n        self.sigmoid = nn.Sigmoid() #elementwise calculation of sigmoid, each layer (class)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.sigmoid(x)\n        return x  ","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:06.403607Z","iopub.execute_input":"2021-12-25T05:10:06.403934Z","iopub.status.idle":"2021-12-25T05:10:06.416680Z","shell.execute_reply.started":"2021-12-25T05:10:06.403903Z","shell.execute_reply":"2021-12-25T05:10:06.415389Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(UNet, self).__init__()\n        self.inc = DoubleConv(in_channels, 64, 3)\n        self.down1 = Down(64, 128, 3)\n        self.down2 = Down(128, 256, 3)\n        self.down3 = Down(256, 512, 3)\n        self.down4 = Down(512, 512, 3)\n        self.up1 = Up(1024, 256)\n        self.up2 = Up(512, 128)\n        self.up3 = Up(256, 64)\n        self.up4 = Up(128, 64)\n        self.outc = out_layer(64, num_classes)  #out layer w/ different classes, each channel w/ binary label\n    def forward(self, x):\n        #print(x)\n        x1 = self.inc(x)\n        #print(x1)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        x = self.outc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:14.489077Z","iopub.execute_input":"2021-12-25T05:10:14.489370Z","iopub.status.idle":"2021-12-25T05:10:14.501271Z","shell.execute_reply.started":"2021-12-25T05:10:14.489338Z","shell.execute_reply":"2021-12-25T05:10:14.500391Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def DiceLoss(inputs, targets, smooth=1):\n        \n    #comment out if your model contains a sigmoid or equivalent activation layer\n    #inputs = F.sigmoid(inputs)       \n        \n    #flatten label and prediction tensors\n    inputs = inputs.view(-1)\n    targets = targets.view(-1)\n        \n    intersection = (inputs * targets).sum()                            \n    dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n    return 1 - dice","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:09.165996Z","iopub.execute_input":"2021-12-25T05:10:09.166315Z","iopub.status.idle":"2021-12-25T05:10:09.172922Z","shell.execute_reply.started":"2021-12-25T05:10:09.166279Z","shell.execute_reply":"2021-12-25T05:10:09.171675Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = UNet(1, 1) #input single channel and output single layer for one class","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:17.276760Z","iopub.execute_input":"2021-12-25T05:10:17.277246Z","iopub.status.idle":"2021-12-25T05:10:17.479516Z","shell.execute_reply.started":"2021-12-25T05:10:17.277214Z","shell.execute_reply":"2021-12-25T05:10:17.478855Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"a = model(images[:3])\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:19.246303Z","iopub.execute_input":"2021-12-25T05:10:19.246935Z","iopub.status.idle":"2021-12-25T05:10:21.818411Z","shell.execute_reply.started":"2021-12-25T05:10:19.246895Z","shell.execute_reply":"2021-12-25T05:10:21.817750Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"b = masks[:3]\nprint(b)\nprint(b.shape)\nl = DiceLoss(a, b)\nprint(l)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:24.692766Z","iopub.execute_input":"2021-12-25T05:10:24.693610Z","iopub.status.idle":"2021-12-25T05:10:24.706543Z","shell.execute_reply.started":"2021-12-25T05:10:24.693561Z","shell.execute_reply":"2021-12-25T05:10:24.705590Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train(model, data_l, learning_rate):\n    cost = []\n    for img, msk in data_l:\n        optimizer.zero_grad()\n        out = model(img.to(device))\n        loss = DiceLoss(out, msk.to(device))\n        loss.backward()\n        optimizer.step()\n        cost.append(loss.item())\n\n    return cost\n\ndef eval_loop(model, optimizer, eval_l):  #evaluate the test set\n    running_loss = 0\n    model.eval()\n    with torch.no_grad():\n        f1_scores, accuracy = [], []\n        for imgs, masks in eval_l:\n            # pass to device\n            imgs = imgs.to(device)\n            masks = masks.to(device)\n            # forward\n            out = model(imgs)\n            loss = DiceLoss(out, masks)\n            running_loss += loss.item()*imgs.shape[0]\n            # calculate predictions using output\n            predicted = (out > 0.5).float()  \n            predicted = predicted.view(-1).cpu().numpy()   #turn tensor to array for accuracy\n            print(predicted)\n            masks = (masks > 0.5).float()  \n            labels = masks.view(-1).cpu().numpy()\n            print(labels)\n            accuracy.append(accuracy_score(labels, predicted))\n            f1_scores.append(f1_score(labels, predicted))\n    acc = sum(accuracy)/len(accuracy)\n    f1 = sum(f1_scores)/len(f1_scores)\n    running_loss /= len(img_test)\n    return acc, f1, running_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:28.187309Z","iopub.execute_input":"2021-12-25T05:10:28.188096Z","iopub.status.idle":"2021-12-25T05:10:28.200853Z","shell.execute_reply.started":"2021-12-25T05:10:28.188038Z","shell.execute_reply":"2021-12-25T05:10:28.200185Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\ndevice = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:10:31.373934Z","iopub.execute_input":"2021-12-25T05:10:31.374432Z","iopub.status.idle":"2021-12-25T05:10:31.379985Z","shell.execute_reply.started":"2021-12-25T05:10:31.374398Z","shell.execute_reply":"2021-12-25T05:10:31.378772Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\"test run with 10 samples\"\nimport itertools\ncost = []\nfor img, msk in itertools.islice(img_load, 10):\n    out = model(img.to(device))\n    loss = DiceLoss(out, msk.to(device))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    cost.append(loss.item())","metadata":{"execution":{"iopub.status.busy":"2021-12-25T00:44:25.135645Z","iopub.execute_input":"2021-12-25T00:44:25.135970Z","iopub.status.idle":"2021-12-25T00:49:05.572268Z","shell.execute_reply.started":"2021-12-25T00:44:25.135937Z","shell.execute_reply":"2021-12-25T00:49:05.570877Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"cost_list = []\nnum_epoch = 5\nfor e in range(num_epoch):\n    mini_cost = train(model, img_load, 0.01)\n    cost_list += mini_cost","metadata":{"execution":{"iopub.status.busy":"2021-12-25T05:15:01.026871Z","iopub.execute_input":"2021-12-25T05:15:01.027357Z","iopub.status.idle":"2021-12-25T06:37:10.265617Z","shell.execute_reply.started":"2021-12-25T05:15:01.027325Z","shell.execute_reply":"2021-12-25T06:37:10.264605Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"plt.plot(cost_list)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-25T06:43:58.349778Z","iopub.execute_input":"2021-12-25T06:43:58.350191Z","iopub.status.idle":"2021-12-25T06:43:58.572437Z","shell.execute_reply.started":"2021-12-25T06:43:58.350152Z","shell.execute_reply":"2021-12-25T06:43:58.571546Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"acc_tot, f_tot, loss_tot = eval_loop(model, optimizer, test_load)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T06:44:12.730643Z","iopub.execute_input":"2021-12-25T06:44:12.731378Z","iopub.status.idle":"2021-12-25T06:44:46.064201Z","shell.execute_reply.started":"2021-12-25T06:44:12.731317Z","shell.execute_reply":"2021-12-25T06:44:46.063259Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(acc_tot, f_tot, loss_tot)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T06:46:36.216106Z","iopub.execute_input":"2021-12-25T06:46:36.216716Z","iopub.status.idle":"2021-12-25T06:46:36.222704Z","shell.execute_reply.started":"2021-12-25T06:46:36.216675Z","shell.execute_reply":"2021-12-25T06:46:36.221990Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = []\n    ground_trues = []\n    imgs_test = []\n    for imgs, masks in test_load:\n        # pass to device\n        imgs = imgs.to(device)\n        masks = masks.to(device)\n        # forward\n        out = model(imgs)\n        predicted = (out > 0.5).float()\n#         print(predicted.shape)\n        outputs.extend(predicted)\n        ground_trues.extend(masks)\n        imgs_test.extend(imgs) ","metadata":{"execution":{"iopub.status.busy":"2021-12-25T06:45:29.016211Z","iopub.execute_input":"2021-12-25T06:45:29.016923Z","iopub.status.idle":"2021-12-25T06:45:59.986294Z","shell.execute_reply.started":"2021-12-25T06:45:29.016880Z","shell.execute_reply":"2021-12-25T06:45:59.985073Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    plt.figure(figsize=(8, 5))\n        \n    plt.subplot(1, 3, 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(imgs_test[i][0].cpu().numpy())\n    plt.title('Original image')\n\n    plt.subplot( 1, 3, 2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(ground_trues[i][0].cpu().numpy())\n    plt.title('Mask')\n\n\n    plt.subplot(1, 3, 3)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(outputs[i][0].cpu().numpy())\n    plt.title('Predicted')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-25T06:46:05.446173Z","iopub.execute_input":"2021-12-25T06:46:05.446623Z","iopub.status.idle":"2021-12-25T06:46:06.819974Z","shell.execute_reply.started":"2021-12-25T06:46:05.446578Z","shell.execute_reply":"2021-12-25T06:46:06.818605Z"},"trusted":true},"execution_count":42,"outputs":[]}]}